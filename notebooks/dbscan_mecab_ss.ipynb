{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vecの分類　（dbscan Scikit-learn）\n",
    "\n",
    "Scikit-learnを使用してクラスター分類を行う。\n",
    "dbscanを調べる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /Users/mfujimak/Library/Python/3.9/lib/python/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/mfujimak/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/mfujimak/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/mfujimak/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/mfujimak/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.5.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /Users/mfujimak/Library/Python/3.9/lib/python/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /Users/mfujimak/Library/Python/3.9/lib/python/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /Users/mfujimak/Library/Python/3.9/lib/python/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/mfujimak/Library/Python/3.9/lib/python/site-packages (from gensim) (6.4.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mecab in /Users/mfujimak/Library/Python/3.9/lib/python/site-packages (0.996.3)\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/formula.jws.json\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/cask.jws.json\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[33mWarning:\u001b[0m mecab 0.996 is already installed and up-to-date.\n",
      "To reinstall 0.996, run:\n",
      "  brew reinstall mecab\n",
      "\u001b[33mWarning:\u001b[0m mecab-ipadic 2.7.0-20070801 is already installed and up-to-date.\n",
      "To reinstall 2.7.0-20070801, run:\n",
      "  brew reinstall mecab-ipadic\n"
     ]
    }
   ],
   "source": [
    "# 使用ライブラリのインストール\n",
    "\n",
    "!pip install -U scikit-learn\n",
    "\n",
    "!pip install --upgrade gensim\n",
    "\n",
    "!pip install  --upgrade mecab\n",
    "\n",
    "!brew install mecab\n",
    "!brew install mecab-ipadic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import silhouette_score\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "def dbscan_cluster_words_with_silhouette(model_path, batch_size, eps_range, min_samples_range):\n",
    "    # Word2Vecモデルの読み込み\n",
    "    model = KeyedVectors.load_word2vec_format(model_path, binary=False)\n",
    "\n",
    "    # 全単語のベクトルを取得\n",
    "    word_vectors = model.vectors\n",
    "    num_words = len(word_vectors)\n",
    "\n",
    "    # eps_range と min_samples_range の組み合わせに対するシルエットスコアを保存\n",
    "    silhouette_scores = []\n",
    "\n",
    "    for eps in eps_range:\n",
    "        for min_samples in min_samples_range:\n",
    "            print(f\"Processing DBSCAN with eps={eps}, min_samples={min_samples}...\")\n",
    "\n",
    "            # バッチ処理を準備\n",
    "            word_cluster_map = {}\n",
    "            dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "\n",
    "            # バッチごとにクラスタリングを実行\n",
    "            for start_idx in range(0, num_words, batch_size):\n",
    "                # バッチ分割\n",
    "                end_idx = min(start_idx + batch_size, num_words)\n",
    "                batch_vectors = word_vectors[start_idx:end_idx]\n",
    "\n",
    "                # DBSCANクラスタリングの実行\n",
    "                cluster_indices = dbscan.fit_predict(batch_vectors)\n",
    "\n",
    "                # バッチごとに単語とクラスタの対応を保存\n",
    "                for i, word in enumerate(model.index_to_key[start_idx:end_idx]):\n",
    "                    word_cluster_map[word] = cluster_indices[i]\n",
    "\n",
    "            # 有効なクラスタ数がある場合のみシルエットスコアを計算\n",
    "            unique_clusters = set(word_cluster_map.values())\n",
    "            if len(unique_clusters) > 1:  # 少なくとも2つのクラスタが必要\n",
    "                cluster_labels = np.array([word_cluster_map[word] for word in model.index_to_key])\n",
    "                score = silhouette_score(word_vectors, cluster_labels)\n",
    "                silhouette_scores.append((eps, min_samples, score))\n",
    "                print(f\"Silhouette Score for eps={eps}, min_samples={min_samples}: {score}\")\n",
    "            else:\n",
    "                silhouette_scores.append((eps, min_samples, None))\n",
    "                print(f\"No valid clusters for eps={eps}, min_samples={min_samples}\")\n",
    "\n",
    "    # 結果を3Dプロット\n",
    "    silhouette_scores = np.array(silhouette_scores)\n",
    "    eps_values = silhouette_scores[:, 0]\n",
    "    min_samples_values = silhouette_scores[:, 1]\n",
    "    scores = silhouette_scores[:, 2]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    sc = ax.scatter(eps_values, min_samples_values, scores, c=scores, cmap='viridis', s=50)\n",
    "    ax.set_xlabel('Eps')\n",
    "    ax.set_ylabel('Min Samples')\n",
    "    ax.set_zlabel('Silhouette Score')\n",
    "    ax.set_title('Silhouette Scores for DBSCAN with Varying Eps and Min Samples')\n",
    "    plt.colorbar(sc, ax=ax, label='Silhouette Score')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DBSCAN with eps=0.1, min_samples=2...\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "\n",
    "model_path = '../data/japanese_word2vec_vectors.vec'\n",
    "batch_size = 1000\n",
    "eps_range = np.linspace(0.1, 1.0, 10)  # epsの範囲を指定\n",
    "min_samples_range = range(2, 21)       # min_samplesの範囲を指定\n",
    "\n",
    "dbscan_cluster_words_with_silhouette(model_path, batch_size, eps_range, min_samples_range)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
